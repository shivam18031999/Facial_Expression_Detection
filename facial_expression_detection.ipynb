{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Detection using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages and modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "session=tf.compat.v1.Session(config=config)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , Dense , MaxPooling2D , Flatten , BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import load_img , img_to_array \n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initally the data is unequaly distributed ,so this leads to biasnes towards a particular class.\n",
    "# so i decided to do image data augmentation , i.e.. creating more data from exsisting data\n",
    "\n",
    "# For the data augmentation , i choose to :\n",
    "\n",
    "# 1. randomly rotate the image \n",
    "# 2. shifting the width and height of image \n",
    "# 3. flipping the image\n",
    "# 4. randomly zooming the image\n",
    "\n",
    "# Datagen1 will generate new image after processing the random operation\n",
    "\n",
    "Datagen1 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# expression represent of each class folder name like angry, sad , happy and so on.\n",
    "for expression in os.listdir('./augmented_facial/images/train'):\n",
    "        \n",
    "        # current expreesion_images is a list of all images name in a paricular class folder \n",
    "        current_expression_images=os.listdir('./augmented_facial/images/train/'+expression)\n",
    "        current_expression_size=len(current_expression_images)\n",
    "        \n",
    "        increasing_factor=0\n",
    "        \n",
    "        # deciding the increasing_factor for generating new images depending upon initial count.\n",
    "        if current_expression_size < 3000:\n",
    "            increasing_factor=12\n",
    "        elif current_expression_size <4500:\n",
    "            increasing_factor=1\n",
    "        \n",
    "        if increasing_factor :\n",
    "               for images in current_expression_images:\n",
    "                            # generating new images corrosponds to each image \n",
    "                            img = load_img('./augmented_facial/images/train/'+expression+'/'+images)\n",
    "                            input_img = img_to_array(img)\n",
    "                            input_img = input_img.reshape((1,)+input_img.shape)\n",
    "                            temp = 1 \n",
    "                            for batch in Datagen1.flow( input_img, batch_size=1,save_to_dir='./augmented_facial/images/train/'+\n",
    "                                                       expression , save_format= \"jpeg\"):\n",
    "                                if temp == increasing_factor:\n",
    "                                    break\n",
    "                                else :\n",
    "                                    temp+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42207 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "42207\n",
      "7066\n"
     ]
    }
   ],
   "source": [
    "# using .flow_from_directory() to upload images \n",
    "# parameters passing :\n",
    "# 1. image path \n",
    "# 2. image size and colour \n",
    "# 3. batch size ( as it divides the data into batches and then pass a single batch a time to the model )\n",
    "# 4. mode of classification \n",
    "\n",
    "batch_size = 64\n",
    "Datagen2 = ImageDataGenerator()\n",
    "\n",
    "training_data = Datagen2.flow_from_directory(\"./augmented_facial/images/train/\",target_size=(48,48),\n",
    "                                                                            color_mode='grayscale',\n",
    "                                                                            batch_size=batch_size,\n",
    "                                                                             class_mode='categorical',\n",
    "                                                                             shuffle=True)\n",
    "\n",
    "validation_data = Datagen2.flow_from_directory(\"./facial/images/validation/\",target_size=(48,48),\n",
    "                                                                            color_mode='grayscale',\n",
    "                                                                            batch_size=batch_size,\n",
    "                                                                             class_mode='categorical',\n",
    "                                                                             shuffle=True)\n",
    "# training ans testing data size \n",
    "\n",
    "print(training_data.n)\n",
    "print(validation_data.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shivamGarg\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we will make our Keras model. Our model will be a seqeuntial model \n",
    "# and generally all the time you can use seqeuntial model only\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# My structure of the model looks something like this:\n",
    "\n",
    "# (Conv2D()-->Conv2D()-->BatchNormalization()-->Maxpooling2D())*2--->Flatten()-->Dense()-->Dense()-->Dense()(output)\n",
    "\n",
    "# first two cnn layer  followed by batchnormalization layer and a max pooling layer \n",
    "# using 64 units in first cnn layer and 128 units in second cnn layer\n",
    "\n",
    "model.add(Conv2D( 64,(3,3),strides=(1,1) , padding=\"same\",activation=\"relu\", input_shape=(48,48,1),use_bias=True))\n",
    "model.add(Conv2D(128,(3,3),strides=(1,1),padding=\"same\",activation=\"relu\",use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n",
    "\n",
    "# next two cnn layer  followed by batchnormalization layer and a max pooling layer \n",
    "# using 256 units in third cnn layer and 512 units in fourth cnn layer\n",
    "\n",
    "model.add(Conv2D( 256,(3,3),strides=(1,1) , padding=\"same\",activation=\"relu\", use_bias=True))\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\",activation=\"relu\",use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n",
    "\n",
    "# flattening the multidimensional output of cnn layer into one dimensional array \n",
    "model.add(Flatten())\n",
    "\n",
    "# using two dense layer in my neural network \n",
    "# first layers contains 256 units and next layer contains 512 units \n",
    "model.add(Dense(256,activation=\"relu\",use_bias=True))\n",
    "model.add(Dense(512,activation=\"relu\",use_bias=True))\n",
    "\n",
    "# output layer with 7 units (each unit corrosponds to one class) \n",
    "model.add(Dense(7,activation=\"softmax\",use_bias=True))\n",
    "\n",
    "# compiling my model\n",
    "# using adam optimizer\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to make the optimizer converge faster and closest to the global minimum of the loss function, \n",
    "# i used an annealing method of the learning rate (LR).\n",
    "# The higher LR, the bigger are the steps and the quicker is the convergence. \n",
    "# However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.\n",
    "# Its better to have a decreasing learning rate during the training to reach \n",
    "# efficiently the global minimum of the loss function.\n",
    "# To keep the advantage of the fast computation time with a high LR, \n",
    "# i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).\n",
    "# With the ReduceLROnPlateau function from Keras.callbacks, \n",
    "# i choose to reduce the LR by 0.2 if the accuracy is not improved after 2 epochs.\n",
    "\n",
    "Reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.1,patience=2,min_lr=0.00001,model=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 110)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of steps in a single epoch\n",
    "# = len(input_data)/batch_size\n",
    "steps_per_epoch = training_data.n // training_data.batch_size\n",
    "validation_steps = validation_data.n // validation_data.batch_size\n",
    "steps_per_epoch , validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shivamGarg\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "659/659 [==============================] - 5398s 8s/step - loss: 2.1420 - accuracy: 0.2702 - val_loss: 2.0795 - val_accuracy: 0.2408\n",
      "Epoch 2/10\n",
      "659/659 [==============================] - 6366s 10s/step - loss: 1.5333 - accuracy: 0.3706 - val_loss: 1.5039 - val_accuracy: 0.4245\n",
      "Epoch 3/10\n",
      "659/659 [==============================] - 5972s 9s/step - loss: 1.3685 - accuracy: 0.4410 - val_loss: 2.6910 - val_accuracy: 0.3245\n",
      "Epoch 4/10\n",
      "659/659 [==============================] - 3970s 6s/step - loss: 1.2480 - accuracy: 0.4932 - val_loss: 1.2857 - val_accuracy: 0.5046\n",
      "Epoch 5/10\n",
      "659/659 [==============================] - 5118s 8s/step - loss: 1.1446 - accuracy: 0.5379 - val_loss: 1.4823 - val_accuracy: 0.5084\n",
      "Epoch 6/10\n",
      "659/659 [==============================] - 3852s 6s/step - loss: 1.0421 - accuracy: 0.5844 - val_loss: 1.1657 - val_accuracy: 0.5181\n",
      "Epoch 7/10\n",
      "659/659 [==============================] - 3809s 6s/step - loss: 0.9280 - accuracy: 0.6347 - val_loss: 1.3236 - val_accuracy: 0.5294\n",
      "Epoch 8/10\n",
      "659/659 [==============================] - 3836s 6s/step - loss: 0.8123 - accuracy: 0.6848 - val_loss: 1.2862 - val_accuracy: 0.5527\n",
      "Epoch 9/10\n",
      "659/659 [==============================] - 3854s 6s/step - loss: 0.6913 - accuracy: 0.7382 - val_loss: 1.2868 - val_accuracy: 0.5424\n",
      "Epoch 10/10\n",
      "659/659 [==============================] - 3861s 6s/step - loss: 0.5873 - accuracy: 0.7822 - val_loss: 1.3529 - val_accuracy: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29b3d7e78d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using .fit_generator() to run my model\n",
    "# using 10 epochs\n",
    "# parameters : input data  and validation data \n",
    "#           : steps per epoch during training and validation steps for testing\n",
    "#           : number of epochs\n",
    "epoch = 10\n",
    "model.fit_generator( training_data , steps_per_epoch = steps_per_epoch , epochs = epoch, \n",
    "                     validation_data = validation_data , validation_steps = validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Model to Json File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting my model to json file\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"mode_json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# storing weights\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
